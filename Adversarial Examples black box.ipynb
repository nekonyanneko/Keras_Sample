{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "from six.moves import xrange\n",
    "\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import flags\n",
    "\n",
    "from cleverhans.utils_mnist import data_mnist\n",
    "from cleverhans.utils import to_categorical\n",
    "from cleverhans.utils import set_log_level\n",
    "from cleverhans.utils_tf import model_train, model_eval, batch_eval\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.attacks_tf import jacobian_graph, jacobian_augmentation\n",
    "\n",
    "from cleverhans_tutorials.tutorial_models import make_basic_cnn, MLP\n",
    "from cleverhans_tutorials.tutorial_models import Flatten, Linear, ReLU, Softmax\n",
    "from cleverhans.utils import TemporaryLogLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_tutorial():\n",
    "    # Set TF random seed to improve reproducibility\n",
    "    tf.set_random_seed(1234)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_bbox(sess, x, y, X_train, Y_train, X_test, Y_test,\n",
    "              nb_epochs, batch_size, learning_rate, rng):\n",
    "    # CNNモデルの定義(これはblackbox modelとして扱う)\n",
    "    model = make_basic_cnn()\n",
    "    predictions = model(x)\n",
    "    print(\"Defined TensorFlow model graph.\")\n",
    "\n",
    "    # MNISTのデータで学習する\n",
    "    train_params = {\n",
    "        'nb_epochs': nb_epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'learning_rate': learning_rate\n",
    "    }\n",
    "    model_train(sess, x, y, predictions, X_train, Y_train, args=train_params, rng=rng)\n",
    "\n",
    "    # 正当なMNISTデータに対する評価\n",
    "    eval_params = {'batch_size': batch_size}\n",
    "    accuracy = model_eval(sess, x, y, predictions, X_test, Y_test, args=eval_params)\n",
    "    print('Test accuracy of black-box on legitimate test examples: ' + str(accuracy))\n",
    "\n",
    "    return model, predictions, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute_model(img_rows=28, img_cols=28, nb_classes=10):\n",
    "    # 攻撃者側が用意するモデル\n",
    "    input_shape = (None, img_rows, img_cols, 1)\n",
    "    # 一般的なDNNモデル\n",
    "    layers = [Flatten(),\n",
    "              Linear(200),\n",
    "              ReLU(),\n",
    "              Linear(200),\n",
    "              ReLU(),\n",
    "              Linear(nb_classes),\n",
    "              Softmax()]\n",
    "\n",
    "    return MLP(layers, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sub(sess, x, y, bbox_preds, X_sub, Y_sub, nb_classes,\n",
    "              nb_epochs_s, batch_size, learning_rate, data_aug, lmbda,\n",
    "              rng):\n",
    "    # 攻撃者が用意したモデルを定義\n",
    "    model_sub = substitute_model()\n",
    "    preds_sub = model_sub(x)\n",
    "    print(\"Defined TensorFlow model graph for the substitute.\")\n",
    "\n",
    "    # Define the Jacobian symbolically using TensorFlow\n",
    "    grads = jacobian_graph(preds_sub, x, nb_classes)\n",
    "\n",
    "    # Train the substitute and augment dataset alternatively\n",
    "    for rho in xrange(data_aug):\n",
    "        print(\"Substitute training epoch #\" + str(rho))\n",
    "        train_params = {\n",
    "            'nb_epochs': nb_epochs_s,\n",
    "            'batch_size': batch_size,\n",
    "            'learning_rate': learning_rate\n",
    "        }\n",
    "        with TemporaryLogLevel(logging.WARNING, \"cleverhans.utils.tf\"):\n",
    "            model_train(sess, x, y, preds_sub, X_sub,\n",
    "                        to_categorical(Y_sub, nb_classes),\n",
    "                        init_all=False, args=train_params, rng=rng)\n",
    "\n",
    "        # If we are not at last substitute training iteration, augment dataset\n",
    "        if rho < data_aug - 1:\n",
    "            print(\"Augmenting substitute training data.\")\n",
    "            # Perform the Jacobian augmentation\n",
    "            lmbda_coef = 2 * int(int(rho / 3) != 0) - 1\n",
    "            X_sub = jacobian_augmentation(sess, x, X_sub, Y_sub, grads,\n",
    "                                          lmbda_coef * lmbda)\n",
    "\n",
    "            print(\"Labeling substitute training data.\")\n",
    "            # Label the newly generated synthetic points using the black-box\n",
    "            Y_sub = np.hstack([Y_sub, Y_sub])\n",
    "            X_sub_prev = X_sub[int(len(X_sub)/2):]\n",
    "            eval_params = {'batch_size': batch_size}\n",
    "            bbox_val = batch_eval(sess, [x], [bbox_preds], [X_sub_prev],\n",
    "                                  args=eval_params)[0]\n",
    "            # Note here that we take the argmax because the adversary\n",
    "            # only has access to the label (not the probabilities) output\n",
    "            # by the black-box model\n",
    "            Y_sub[int(len(X_sub)/2):] = np.argmax(bbox_val, axis=1)\n",
    "\n",
    "    return model_sub, preds_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_blackbox(train_start=0, train_end=60000, test_start=0,\n",
    "                   test_end=10000, nb_classes=10, batch_size=128,\n",
    "                   learning_rate=0.001, nb_epochs=1, holdout=150, data_aug=6,\n",
    "                   nb_epochs_s=1, lmbda=0.1):\n",
    "\n",
    "    set_log_level(logging.DEBUG)\n",
    "    accuracies = {}\n",
    "    assert setup_tutorial()\n",
    "\n",
    "    sess = tf.Session()\n",
    "\n",
    "    # Get MNIST data\n",
    "    X_train, Y_train, X_test, Y_test = data_mnist(train_start=train_start,\n",
    "                                                  train_end=train_end,\n",
    "                                                  test_start=test_start,\n",
    "                                                  test_end=test_end)\n",
    "    X_sub = X_test[:holdout]\n",
    "    Y_sub = np.argmax(Y_test[:holdout], axis=1)\n",
    "    X_test = X_test[holdout:]\n",
    "    Y_test = Y_test[holdout:]\n",
    "\n",
    "    # Define input and output TF placeholders\n",
    "    x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
    "    y = tf.placeholder(tf.float32, shape=(None, 10))\n",
    "\n",
    "    rng = np.random.RandomState([2017, 8, 30])\n",
    "\n",
    "    # blackboxモデルのシミュレート\n",
    "    # prep_bbox内部では学習しているが、実際にはApplicationなどの戻り値から\n",
    "    print(\"Preparing the black-box model.\")\n",
    "    prep_bbox_out = prep_bbox(sess, x, y, X_train, Y_train, X_test, Y_test,\n",
    "                              nb_epochs, batch_size, learning_rate,\n",
    "                              rng=rng)\n",
    "    model, bbox_preds, accuracies['bbox'] = prep_bbox_out\n",
    "\n",
    "    # 攻撃者側のモデルで学習\n",
    "    print(\"Training the substitute model.\")\n",
    "    train_sub_out = train_sub(sess, x, y, bbox_preds, X_sub, Y_sub,\n",
    "                              nb_classes, nb_epochs_s, batch_size,\n",
    "                              learning_rate, data_aug, lmbda, rng=rng)\n",
    "    model_sub, preds_sub = train_sub_out\n",
    "\n",
    "    # Evaluate the substitute model on clean test examples\n",
    "    eval_params = {'batch_size': batch_size}\n",
    "    acc = model_eval(sess, x, y, preds_sub, X_test, Y_test, args=eval_params)\n",
    "    accuracies['sub'] = acc\n",
    "\n",
    "    # 攻撃はFast Gradient Sign Method (FGSM) を利用する\n",
    "    # また、攻撃者が用意したモデルでAdversarial Examplesを生成する\n",
    "    fgsm_par = {'eps': 0.3, 'ord': np.inf, 'clip_min': 0., 'clip_max': 1.}\n",
    "    fgsm = FastGradientMethod(model_sub, sess=sess)\n",
    "    eval_params = {'batch_size': batch_size}\n",
    "    x_adv_sub = fgsm.generate(x, **fgsm_par)\n",
    "\n",
    "    # 攻撃者が用意したモデルで作成したAdversarial Exsamplesでblackboxモデルを評価する\n",
    "    accuracy = model_eval(sess, x, y, model(x_adv_sub), X_test, Y_test, args=eval_params)\n",
    "    print('Test accuracy of oracle on adversarial examples generated using the substitute: ' + str(accuracy))\n",
    "    accuracies['bbox_on_sub_adv_ex'] = accuracy\n",
    "\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/t10k-labels-idx1-ubyte.gz\n",
      "X_train shape: (60000, 28, 28, 1)\n",
      "X_test shape: (10000, 28, 28, 1)\n",
      "Preparing the black-box model.\n",
      "WARNING:tensorflow:From /home/jovyan/src/cleverhans/cleverhans_tutorials/tutorial_models.py:79: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Defined TensorFlow model graph.\n",
      "WARNING:tensorflow:From /home/jovyan/src/cleverhans/cleverhans/utils_tf.py:37: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-05-30 06:21:29,915 cleverhans] Epoch 0 took 122.29941654205322 seconds\n",
      "[INFO 2018-05-30 06:21:29,916 cleverhans] Completed model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of black-box on legitimate test examples: 0.9825380710659899\n",
      "Training the substitute model.\n",
      "Defined TensorFlow model graph for the substitute.\n",
      "Substitute training epoch #0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-05-30 06:21:33,905 cleverhans] Epoch 0 took 0.033161163330078125 seconds\n",
      "[INFO 2018-05-30 06:21:33,909 cleverhans] Completed model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      "Substitute training epoch #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-05-30 06:21:38,686 cleverhans] Epoch 0 took 0.03509664535522461 seconds\n",
      "[INFO 2018-05-30 06:21:38,688 cleverhans] Completed model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      "Substitute training epoch #2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-05-30 06:21:50,994 cleverhans] Epoch 0 took 0.0447850227355957 seconds\n",
      "[INFO 2018-05-30 06:21:50,996 cleverhans] Completed model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      "Substitute training epoch #3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-05-30 06:22:26,987 cleverhans] Epoch 0 took 0.07931804656982422 seconds\n",
      "[INFO 2018-05-30 06:22:26,988 cleverhans] Completed model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting substitute training data.\n",
      "Labeling substitute training data.\n",
      "Substitute training epoch #4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2018-05-30 06:28:07,103 cleverhans] Epoch 0 took 0.42368578910827637 seconds\n",
      "[INFO 2018-05-30 06:28:07,122 cleverhans] Completed model training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting substitute training data.\n"
     ]
    }
   ],
   "source": [
    "mnist_blackbox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
